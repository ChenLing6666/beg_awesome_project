{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "import datetime\n",
    "from google.cloud import aiplatform\n",
    "from flask import Flask, render_template\n",
    "\n",
    "from google.auth import credentials\n",
    "from google.oauth2 import service_account\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from vertexai.preview.language_models import ChatModel, InputOutputTextPair\n",
    "import vertexai\n",
    "import json  # add this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard_resource:Creating Tensorboard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tensorboard backing LRO: projects/958932094048/locations/us-east1/tensorboards/1457758904384487424/operations/8093409984303333376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard_resource:Create Tensorboard backing LRO: projects/958932094048/locations/us-east1/tensorboards/1457758904384487424/operations/8093409984303333376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard created. Resource name: projects/958932094048/locations/us-east1/tensorboards/1457758904384487424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard_resource:Tensorboard created. Resource name: projects/958932094048/locations/us-east1/tensorboards/1457758904384487424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this Tensorboard in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard_resource:To use this Tensorboard in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tb = aiplatform.Tensorboard('projects/958932094048/locations/us-east1/tensorboards/1457758904384487424')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.tensorboard.tensorboard_resource:tb = aiplatform.Tensorboard('projects/958932094048/locations/us-east1/tensorboards/1457758904384487424')\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(\n",
    "    # your Google Cloud Project ID or number\n",
    "    # environment default used is not set\n",
    "    project='ambient-mystery-292420',\n",
    "\n",
    "    # the Vertex AI region you will use\n",
    "    # defaults to us-central1\n",
    "    location='us-east1',\n",
    "\n",
    "    # Google Cloud Storage bucket in same region as location\n",
    "    # used to stage artifacts\n",
    "    staging_bucket='gs://awesome_ai_project_test_07_09',\n",
    "\n",
    "    # custom google.auth.credentials.Credentials\n",
    "    # environment default creds used if not set\n",
    "    credentials=my_credentials,\n",
    "\n",
    "    # # customer managed encryption key resource name\n",
    "    # # will be applied to all Vertex AI resources if set\n",
    "    # encryption_spec_key_name=my_encryption_key_name,\n",
    "\n",
    "    # the name of the experiment to use to track\n",
    "    # logged metrics and parameters\n",
    "    experiment='my-experiment',\n",
    "\n",
    "    # description of the experiment above\n",
    "    experiment_description='my experiment decsription'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Publisher Model `publishers/google/models/chat-bison@001` is not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/grpc/_channel.py:1030\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1028\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/grpc/_channel.py:910\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Publisher Model `publishers/google/models/chat-bison@001` is not found.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.40.202:443 {grpc_message:\"Publisher Model `publishers/google/models/chat-bison@001` is not found.\", grpc_status:5, created_time:\"2023-07-09T14:51:31.536669-04:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvertexai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreview\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlanguage_models\u001b[39;00m \u001b[39mimport\u001b[39;00m (ChatModel, InputOutputTextPair,\n\u001b[1;32m      2\u001b[0m                                               TextEmbeddingModel,\n\u001b[1;32m      3\u001b[0m                                               TextGenerationModel)\n\u001b[0;32m----> 4\u001b[0m chat_model \u001b[39m=\u001b[39m ChatModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mchat-bison@001\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m chat \u001b[39m=\u001b[39m chat_model\u001b[39m.\u001b[39mstart_chat(\n\u001b[1;32m      7\u001b[0m     context\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMy name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     examples\u001b[39m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m chat\u001b[39m.\u001b[39msend_message(\u001b[39m\"\u001b[39m\u001b[39mDo you know any cool events this weekend?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/vertexai/_model_garden/_model_garden_models.py:211\u001b[0m, in \u001b[0;36m_ModelGardenModel.from_pretrained\u001b[0;34m(cls, model_name)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_INSTANCE_SCHEMA_URI:\n\u001b[1;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClass \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is not a correct model interface class since it does not have an instance schema URI.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 211\u001b[0m model_info \u001b[39m=\u001b[39m _get_model_info(\n\u001b[1;32m    212\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_name, schema_to_class_map\u001b[39m=\u001b[39;49m{\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_INSTANCE_SCHEMA_URI: \u001b[39mcls\u001b[39;49m}\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39missubclass\u001b[39m(model_info\u001b[39m.\u001b[39minterface_class, \u001b[39mcls\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m is of type \u001b[39m\u001b[39m{\u001b[39;00mmodel_info\u001b[39m.\u001b[39minterface_class\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m not of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/vertexai/_model_garden/_model_garden_models.py:93\u001b[0m, in \u001b[0;36m_get_model_info\u001b[0;34m(model_id, schema_to_class_map)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_id:\n\u001b[1;32m     90\u001b[0m     model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpublishers/google/models/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model_id\n\u001b[1;32m     92\u001b[0m publisher_model_res \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 93\u001b[0m     _publisher_models\u001b[39m.\u001b[39;49m_PublisherModel(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     94\u001b[0m         resource_name\u001b[39m=\u001b[39;49mmodel_id\n\u001b[1;32m     95\u001b[0m     )\u001b[39m.\u001b[39m_gca_resource\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m publisher_model_res\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mpublishers/google/models/\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOnly Google models are currently supported. \u001b[39m\u001b[39m{\u001b[39;00mpublisher_model_res\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/cloud/aiplatform/_publisher_models.py:77\u001b[0m, in \u001b[0;36m_PublisherModel.__init__\u001b[0;34m(self, resource_name, project, location, credentials)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     73\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mresource_name\u001b[39m}\u001b[39;00m\u001b[39m` is not a valid PublisherModel resource \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mname or model garden id.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gca_resource \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getter_method)(\n\u001b[1;32m     78\u001b[0m     name\u001b[39m=\u001b[39;49mfull_resource_name, retry\u001b[39m=\u001b[39;49mbase\u001b[39m.\u001b[39;49m_DEFAULT_RETRY\n\u001b[1;32m     79\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/model_garden_service/client.py:536\u001b[0m, in \u001b[0;36mModelGardenServiceClient.get_publisher_model\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    531\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[1;32m    532\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mname),)),\n\u001b[1;32m    533\u001b[0m )\n\u001b[1;32m    535\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    537\u001b[0m     request,\n\u001b[1;32m    538\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    539\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    540\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    541\u001b[0m )\n\u001b[1;32m    543\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/awesome_beg_project/beg_project/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Publisher Model `publishers/google/models/chat-bison@001` is not found."
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import (ChatModel, InputOutputTextPair,\n",
    "                                              TextEmbeddingModel,\n",
    "                                              TextGenerationModel)\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "\n",
    "chat = chat_model.start_chat(\n",
    "    context=\"My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\",\n",
    "    examples=[\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"Who do you work for?\",\n",
    "            output_text=\"I work for Ned.\",\n",
    "        ),\n",
    "        InputOutputTextPair(\n",
    "            input_text=\"What do I like?\",\n",
    "            output_text=\"Ned likes watching movies.\",\n",
    "        ),\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "chat.send_message(\"Do you know any cool events this weekend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beg_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
